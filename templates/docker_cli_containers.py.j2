#!/usr/bin/env python

import argparse
import docker
import hashlib
import json
import os
import time
import sys

# Return dict
content=dict({
    'containers': [],
    'containers_count': 0
})

# Global variables
# strict list of attributes to extract from docker containers
attributes_whitelist = [
    'Name', 'Names',
    'State', 'Id'
]

def attributes_map_state(state):
    if isinstance(state, str):
        if state in ['running']:
            return 1
        return 0
    elif isinstance(state, dict):
        return attributes_map_state(state['Status'])

# mapping for return values
attributes_map = {
    'STATE': attributes_map_state
}

# number of second to cache a query result
local_query_cache_life = 55
local_query_cache_path = '/tmp/zbx_dck_cqc_{}.json'.format(hashlib.md5(os.getenv('USER').encode()).hexdigest())
local_query_cache_lock_path = local_query_cache_path+'.lock'

os.environ['DOCKER_HOST']='{{ docker_server__clients_host }}'


def LockException(BaseException):
    pass

def acquireLock():
    tries = 0
    # wait if lock is acquired
    while os.path.isfile(local_query_cache_lock_path):
        tries += 1
        if tries > 14:
            raise LockException('unable to acquire lock')
        time.sleep(0.1)
    with open(local_query_cache_lock_path, 'w') as f:
        pass
    return True

def releaseLock():
    if os.path.isfile(local_query_cache_lock_path):
        os.unlink(local_query_cache_lock_path)
    return True

def normalizeContainers(c):
    # normalize name
    if 'NAME' in c:
        name = c['NAME']
    else:
        name = c['NAMES'][0]
        del c['NAMES']
    if name[0].startswith('/'):
        name = name.split('/')[1]
    c['NAME'] = name
    # map values according to defined mapping
    for key in c:
        if key in attributes_map and callable(attributes_map[key]):
            c[key] = attributes_map[key](c[key])
    return c

def getContainers(cache=True):
    # generate cache
    if (not cache or
        not os.path.isfile(local_query_cache_path) or
        time.time() - os.stat(local_query_cache_path).st_mtime > local_query_cache_life):
        try:
            client = docker.from_env()
            containers = list(
                            map(normalizeContainers,
                                map(lambda x: dict(
                                                map(lambda x: (x[0].upper(), x[1]),
                                                    filter(lambda x: x[0] in attributes_whitelist,
                                                            list((x.attrs if hasattr(x, 'attrs') else x).items())
                                                        )
                                                    )
                                                ),
                                    client.containers.list() if hasattr(client.containers, 'list') else client.containers()
                                ),
                            )
                        )
            if not cache:
                return containers
            acquireLock()
            with open(local_query_cache_path, 'w') as f:
                json.dump(containers, f)
        except Exception as e:
            raise e
        finally:
            releaseLock()
    # use cache
    else:
        try:
            acquireLock()
            with open(local_query_cache_path, 'r') as f:
                containers = json.load(f)
        except Exception as e:
            raise e
        finally:
            releaseLock()
    return containers


## RETRIEVE INFORMATIONS
if __name__ == "__main__":
    # Create parser
    parser = argparse.ArgumentParser(description='Command line utility to query containers from docker daemon')
    action_group = parser.add_mutually_exclusive_group()
    action_group.add_argument('--count', action='store_true', help='Return only the current containers count')
    action_group.add_argument('--discovery', action='store_true', help='Return an array of containers attributes to use to create templated items')
    action_group.add_argument('--container', action='store', dest='container_name', nargs='?', default=None,
                                help='Return only attributes of this given container name')

    parser.add_argument('--zabbix', action='store_const', const='zabbix', dest='discovery_format', default=None,
                                help='Set output format for zabbix')
    parser.add_argument('--no-cache', action='store_true', dest='use_cache', default=False,
                                help='Disable caching of docker queries')

    args = parser.parse_args()

    content['containers'] = getContainers(cache=args.use_cache)
    content['containers_count'] = len(content['containers'])

    ## OUTPUT
    if args.count:
        content = content['containers_count']
    elif args.discovery:
        if args.discovery_format == 'zabbix':
            data = []
            for container in content['containers']:
                item = dict()
                for key in container:
                    item['{{ '{#' }}'+key+'}'] = container[key]
                data.append(item)
            content = dict({"data": data})
        else:
            print('you must choose an output format for discovery informations')
            sys.exit(1)
    elif args.container_name:
        result = filter(lambda x: x['NAME'] == args.container_name, content['containers'])
        if len(result):
            content = result[0]
        else:
            content = None
    print(json.dumps(content))
sys.exit(0)
